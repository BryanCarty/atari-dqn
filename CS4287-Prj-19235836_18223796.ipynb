{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Reinforcement Learning\n",
    "## Implementation of an Atari Breakout RL Agent using a Double Deep Q Network\n",
    "\n",
    "Team memebers: Bryan Carty (19235836) & Eoin Chedzey (18223796)<br>\n",
    "This code executes all the way through, without an error.<br>\n",
    "Our code is based on the Atari Breakout implementation in the book 'Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow' by Aurélien Géron. The jupyter notebook covering the reinforcement learning chapter can be found at: https://github.com/ageron/handson-ml2/blob/master/18_reinforcement_learning.ipynb\n",
    "\n",
    "With the exception of a few hyperparameters, the hyperparameters we found to be optimal correspond to those outlined in the 'Human-level control through deep reinforcement learning' paper by DeepMind in 2015. It can be found at: https://www.nature.com/articles/nature14236?wm=book_wap_0005<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double DQN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments import suite_atari # Suite for loading Atari Gym environments\n",
    "from tf_agents.environments.atari_preprocessing import AtariPreprocessing # Does the same preprocessing as was done on Nature's 2015 DQN paper\n",
    "from tf_agents.environments.atari_wrappers import FrameStack4 # Stacks previous 4 frames\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episode_steps = 27000 # 4 frames per step, so a max of 108k frames per episode\n",
    "environment_name = \"BreakoutNoFrameskip-v4\" # Environment does not have frame skipping by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom class to perform preprocessing on Atari Breakout Frames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariPreprocessingWithAutoFire(AtariPreprocessing):\n",
    "    def reset(self, **kwargs):\n",
    "        obs = super().reset(**kwargs)\n",
    "        super().step(1) # FIRE to start\n",
    "        return obs\n",
    "    def step(self, action):\n",
    "        lives_before_action = self.ale.lives()\n",
    "        obs, rewards, done, info = super().step(action) # done is true when a life is lost and terminal_on_life_loss, or when the episode is over.\n",
    "        if self.ale.lives() < lives_before_action and not done: \n",
    "            super().step(1) # FIRE to start after life lost\n",
    "        return obs, rewards, done, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Atari Breakout Environment (wrapped with preprocessing and framestacking)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = suite_atari.load( \n",
    "    environment_name, # Load a wrapped BreakoutNoFrameskip environment, with a max of 27,000 steps per episode.\n",
    "    max_episode_steps=max_episode_steps, # AtariPreprocessing wrapper implements same preprocessing done in 2015 DQN paper e.g. convert to greyscale, scale to 84 x 84 pixels, implement frame skipping (4 frames). Hover over AtariPreprocessing to see the rest.\n",
    "    gym_env_wrappers=[AtariPreprocessingWithAutoFire, FrameStack4] # In addition to frame skipping, these skipped frames are stacked, one on top of another (deciphers velocity). Stack size = 4.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display what preprocessed observation looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure preprocessed_breakout_observation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(\"images\", fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "env.seed(42)\n",
    "env.reset()\n",
    "for _ in range(4): # 4 as 4 frames are stacked together\n",
    "    time_step = env.step(3) # Move left\n",
    "\n",
    "def plot_observation(obs): # function to plot observation\n",
    "    # red = 3 time steps ago\n",
    "    # green = 2 time steps ago\n",
    "    # blue = previous frame\n",
    "    # purple = current frame\n",
    "    obs = obs.astype(np.float32)\n",
    "    img = obs[..., :3]\n",
    "    current_frame_delta = np.maximum(obs[..., 3] - obs[..., :3].mean(axis=-1), 0.)\n",
    "    img[..., 0] += current_frame_delta\n",
    "    img[..., 2] += current_frame_delta\n",
    "    img = np.clip(img / 150, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.figure(figsize=(6, 6))\n",
    "plot_observation(time_step.observation)\n",
    "save_fig(\"preprocessed_breakout_observation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wrap the environment inside a TFPyEnvironment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
    "tf_env = TFPyEnvironment(env) # We wrap the environment inside a TFPyEnvironment. This will make the environment usable within a Tensorflow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Q Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.networks.q_network import QNetwork # Q Network -> takes an observation as input and outputs 1 Q-Value per action.\n",
    "preprocessing_layer = tf.keras.layers.Lambda(lambda obs: tf.cast(obs, np.float32)/255.) # This layer casts the observations to 32 bit floats and normalizes them (values will range from 0.0 -> 1.0)\n",
    "conv_layer_params = [(32, (8,8), 4), (64, (4,4), 2), (64, (3,3), 1)] # 3 convolution layers -> a layer being (num filters, (filter dimensions), stride)\n",
    "fc_layer_params = [512] # a dense layer with 512 units. This layer is followed by a dense layer with 4 units -> 1 per action. Outputs Q value.\n",
    "                    # input tensor spec, action tensor spec, preprocessing layer, conv layer, fully connected layer params.\n",
    "q_net = QNetwork(tf_env.observation_spec(), tf_env.action_spec(), preprocessing_layers=preprocessing_layer, conv_layer_params=conv_layer_params, fc_layer_params=fc_layer_params, kernel_initializer=tf.initializers.glorot_uniform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and initialize DQN Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mRMSprop(learning_rate\u001b[39m=\u001b[39m\u001b[39m2.5e-4\u001b[39m, rho\u001b[39m=\u001b[39m\u001b[39m0.95\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, epsilon\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m, centered\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m# same hyperparameters as in 2015 DQN paper.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m epsilon_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mschedules\u001b[39m.\u001b[39mPolynomialDecay( \u001b[39m# will compute epsilon for a given training step. Will go from 1.0 to 0.001. The value used in 2015 DQN paper is 1,000,000 frames so 250,000 steps. But since we're training every 4 steps (16 frames), we'll decay over 62,500 training steps\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     initial_learning_rate\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m,\n\u001b[0;32m      7\u001b[0m     decay_steps\u001b[39m=\u001b[39m \u001b[39m250000\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m update_period, \u001b[39m# number of decay steps # 1,000,000 ALE frames  # // Performs floor-division on the values on either side. Then assigns it to the expression on the left.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     end_learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m agent \u001b[39m=\u001b[39m DqnAgent( \u001b[39m# Creates a DQN Agent\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     tf_env\u001b[39m.\u001b[39mtime_step_spec(), \n\u001b[0;32m     12\u001b[0m     tf_env\u001b[39m.\u001b[39maction_spec(), \n\u001b[0;32m     13\u001b[0m     q_network\u001b[39m=\u001b[39mq_net, \n\u001b[0;32m     14\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer, \n\u001b[0;32m     15\u001b[0m     target_update_period\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m, \u001b[39m# Period for soft update of the target networks. 2000 x 4 = 8000, 8000 x 4 = 32,000 ALE Frames.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     td_errors_loss_fn\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mHuber(reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m# The Huber loss function can be used to balance between the Mean Absolute Error and the Mean Squared Error. It is therefore a good loss function for when you have varied data or only a few outliers. Reduction is none so it returns error per instance not the mean error.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     gamma\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m, \u001b[39m# discount factor\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     train_step_counter\u001b[39m=\u001b[39mtrain_step, \u001b[39m# counts number of training steps\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     epsilon_greedy\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m: epsilon_fn(train_step) \u001b[39m# function to compute epsilon for a given training step.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m agent\u001b[39m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gin\\config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39mnew_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_agents\\agents\\dqn\\dqn_agent.py:239\u001b[0m, in \u001b[0;36mDqnAgent.__init__\u001b[1;34m(self, time_step_spec, action_spec, q_network, optimizer, observation_and_action_constraint_splitter, epsilon_greedy, n_step_update, boltzmann_temperature, emit_log_probability, target_q_network, target_update_tau, target_update_period, td_errors_loss_fn, gamma, reward_scale_factor, gradient_clipping, debug_summaries, summarize_grads_and_vars, train_step_counter, training_data_spec, name)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m observation_and_action_constraint_splitter:\n\u001b[0;32m    237\u001b[0m   net_observation_spec, _ \u001b[39m=\u001b[39m observation_and_action_constraint_splitter(\n\u001b[0;32m    238\u001b[0m       net_observation_spec)\n\u001b[1;32m--> 239\u001b[0m q_network\u001b[39m.\u001b[39;49mcreate_variables(net_observation_spec)\n\u001b[0;32m    240\u001b[0m \u001b[39mif\u001b[39;00m target_q_network:\n\u001b[0;32m    241\u001b[0m   target_q_network\u001b[39m.\u001b[39mcreate_variables(net_observation_spec)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_agents\\networks\\network.py:221\u001b[0m, in \u001b[0;36mNetwork.create_variables\u001b[1;34m(self, input_tensor_spec, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m initial_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_initial_state(batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    220\u001b[0m step_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfill((\u001b[39m1\u001b[39m,), time_step\u001b[39m.\u001b[39mStepType\u001b[39m.\u001b[39mFIRST)\n\u001b[1;32m--> 221\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\n\u001b[0;32m    222\u001b[0m     random_input,\n\u001b[0;32m    223\u001b[0m     step_type\u001b[39m=\u001b[39mstep_type,\n\u001b[0;32m    224\u001b[0m     network_state\u001b[39m=\u001b[39minitial_state,\n\u001b[0;32m    225\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    227\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_calc_unbatched_spec\u001b[39m(x):\n\u001b[0;32m    228\u001b[0m   \u001b[39m\"\"\"Build Network output spec by removing previously added batch dimension.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \n\u001b[0;32m    230\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[39m    Specs without batch dimension representing x.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_agents\\networks\\network.py:427\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mis_tensor(network_state)\n\u001b[0;32m    422\u001b[0m     \u001b[39mand\u001b[39;00m network_state \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, ())\n\u001b[0;32m    423\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnetwork_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m call_argspec\u001b[39m.\u001b[39margs\n\u001b[0;32m    424\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m call_argspec\u001b[39m.\u001b[39mkeywords):\n\u001b[0;32m    425\u001b[0m   normalized_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mnetwork_state\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 427\u001b[0m outputs, new_state \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(Network, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormalized_kwargs)  \u001b[39m# pytype: disable=attribute-error  # typed-keras\u001b[39;00m\n\u001b[0;32m    429\u001b[0m nest_utils\u001b[39m.\u001b[39massert_matching_dtypes_and_inner_shapes(\n\u001b[0;32m    430\u001b[0m     new_state,\n\u001b[0;32m    431\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_spec,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m     tensors_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`new_state`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    435\u001b[0m     specs_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`state_spec`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m \u001b[39mreturn\u001b[39;00m outputs, new_state\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_agents\\networks\\q_network.py:147\u001b[0m, in \u001b[0;36mQNetwork.call\u001b[1;34m(self, observation, step_type, network_state, training)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, observation, step_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, network_state\u001b[39m=\u001b[39m(), training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    135\u001b[0m   \u001b[39m\"\"\"Runs the given observation through the network.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39m    A tuple `(logits, network_state)`.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 147\u001b[0m   state, network_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_encoder(\n\u001b[0;32m    148\u001b[0m       observation, step_type\u001b[39m=\u001b[39;49mstep_type, network_state\u001b[39m=\u001b[39;49mnetwork_state,\n\u001b[0;32m    149\u001b[0m       training\u001b[39m=\u001b[39;49mtraining)\n\u001b[0;32m    150\u001b[0m   q_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_q_value_layer(state, training\u001b[39m=\u001b[39mtraining)\n\u001b[0;32m    151\u001b[0m   \u001b[39mreturn\u001b[39;00m q_value, network_state\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_agents\\networks\\network.py:427\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mis_tensor(network_state)\n\u001b[0;32m    422\u001b[0m     \u001b[39mand\u001b[39;00m network_state \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, ())\n\u001b[0;32m    423\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnetwork_state\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m call_argspec\u001b[39m.\u001b[39margs\n\u001b[0;32m    424\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m call_argspec\u001b[39m.\u001b[39mkeywords):\n\u001b[0;32m    425\u001b[0m   normalized_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mnetwork_state\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 427\u001b[0m outputs, new_state \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(Network, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnormalized_kwargs)  \u001b[39m# pytype: disable=attribute-error  # typed-keras\u001b[39;00m\n\u001b[0;32m    429\u001b[0m nest_utils\u001b[39m.\u001b[39massert_matching_dtypes_and_inner_shapes(\n\u001b[0;32m    430\u001b[0m     new_state,\n\u001b[0;32m    431\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_spec,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m     tensors_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`new_state`\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    435\u001b[0m     specs_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`state_spec`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m \u001b[39mreturn\u001b[39;00m outputs, new_state\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_agents\\networks\\encoding_network.py:328\u001b[0m, in \u001b[0;36mEncodingNetwork.call\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    325\u001b[0m   states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocessing_combiner(states)\n\u001b[0;32m    327\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_postprocessing_layers:\n\u001b[1;32m--> 328\u001b[0m   states \u001b[39m=\u001b[39m layer(states, training\u001b[39m=\u001b[39;49mtraining)\n\u001b[0;32m    330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_squash:\n\u001b[0;32m    331\u001b[0m   states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(batch_squash\u001b[39m.\u001b[39munflatten, states)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1094\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1096\u001b[0m ):\n\u001b[1;32m-> 1097\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1099\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:283\u001b[0m, in \u001b[0;36mConv.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    279\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compiled_convolution_op(\n\u001b[0;32m    280\u001b[0m         inputs, tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel)\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvolution_op(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel)\n\u001b[0;32m    285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[0;32m    286\u001b[0m     output_rank \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:255\u001b[0m, in \u001b[0;36mConv.convolution_op\u001b[1;34m(self, inputs, kernel)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     tf_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding\n\u001b[1;32m--> 255\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mconvolution(\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     kernel,\n\u001b[0;32m    258\u001b[0m     strides\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrides),\n\u001b[0;32m    259\u001b[0m     padding\u001b[39m=\u001b[39;49mtf_padding,\n\u001b[0;32m    260\u001b[0m     dilations\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation_rate),\n\u001b[0;32m    261\u001b[0m     data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tf_data_format,\n\u001b[0;32m    262\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    263\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1181\u001b[0m, in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnn.convolution\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m   1172\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvolution_v2\u001b[39m(  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     dilations\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1180\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1181\u001b[0m   \u001b[39mreturn\u001b[39;00m convolution_internal(\n\u001b[0;32m   1182\u001b[0m       \u001b[39minput\u001b[39;49m,  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;49;00m\n\u001b[0;32m   1183\u001b[0m       filters,\n\u001b[0;32m   1184\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[0;32m   1185\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   1186\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   1187\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[0;32m   1188\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:1313\u001b[0m, in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1310\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1311\u001b[0m     op \u001b[39m=\u001b[39m conv1d\n\u001b[1;32m-> 1313\u001b[0m   \u001b[39mreturn\u001b[39;00m op(\n\u001b[0;32m   1314\u001b[0m       \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   1315\u001b[0m       filters,\n\u001b[0;32m   1316\u001b[0m       strides,\n\u001b[0;32m   1317\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   1318\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   1319\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[0;32m   1320\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   1321\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m   \u001b[39mif\u001b[39;00m channel_index \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:2787\u001b[0m, in \u001b[0;36m_conv2d_expanded_batch\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2783\u001b[0m input_rank \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m   2784\u001b[0m \u001b[39mif\u001b[39;00m input_rank \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m input_rank \u001b[39m<\u001b[39m \u001b[39m5\u001b[39m:\n\u001b[0;32m   2785\u001b[0m   \u001b[39m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[39;00m\n\u001b[0;32m   2786\u001b[0m   \u001b[39m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[39;00m\n\u001b[1;32m-> 2787\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_nn_ops\u001b[39m.\u001b[39;49mconv2d(\n\u001b[0;32m   2788\u001b[0m       \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   2789\u001b[0m       \u001b[39mfilter\u001b[39;49m\u001b[39m=\u001b[39;49mfilters,\n\u001b[0;32m   2790\u001b[0m       strides\u001b[39m=\u001b[39;49mstrides,\n\u001b[0;32m   2791\u001b[0m       padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[0;32m   2792\u001b[0m       data_format\u001b[39m=\u001b[39;49mdata_format,\n\u001b[0;32m   2793\u001b[0m       dilations\u001b[39m=\u001b[39;49mdilations,\n\u001b[0;32m   2794\u001b[0m       name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2795\u001b[0m \u001b[39mreturn\u001b[39;00m squeeze_batch_dims(\n\u001b[0;32m   2796\u001b[0m     \u001b[39minput\u001b[39m,\n\u001b[0;32m   2797\u001b[0m     functools\u001b[39m.\u001b[39mpartial(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2804\u001b[0m     inner_rank\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m   2805\u001b[0m     name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1100\u001b[0m, in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   1099\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   1101\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mConv2D\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, \u001b[39mfilter\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrides\u001b[39;49m\u001b[39m\"\u001b[39;49m, strides,\n\u001b[0;32m   1102\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39muse_cudnn_on_gpu\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_cudnn_on_gpu, \u001b[39m\"\u001b[39;49m\u001b[39mpadding\u001b[39;49m\u001b[39m\"\u001b[39;49m, padding,\n\u001b[0;32m   1103\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mexplicit_paddings\u001b[39;49m\u001b[39m\"\u001b[39;49m, explicit_paddings, \u001b[39m\"\u001b[39;49m\u001b[39mdata_format\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_format,\n\u001b[0;32m   1104\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mdilations\u001b[39;49m\u001b[39m\"\u001b[39;49m, dilations)\n\u001b[0;32m   1105\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   1106\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent # Implements the DQN algorithm from \"Human level control through deep reinforcement learning\" Mnih et al., 2015\n",
    "train_step = tf.Variable(0) # counts the number of training steps\n",
    "update_period = 4 # train the model every 4 steps\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=2.5e-4, rho=0.95, momentum=0.0, epsilon=0.00001, centered=True) # same hyperparameters as in 2015 DQN paper.\n",
    "epsilon_fn = tf.keras.optimizers.schedules.PolynomialDecay( # will compute epsilon for a given training step. Will go from 1.0 to 0.001. The value used in 2015 DQN paper is 1,000,000 frames so 250,000 steps. But since we're training every 4 steps (16 frames), we'll decay over 62,500 training steps\n",
    "    initial_learning_rate=1.0,\n",
    "    decay_steps= 250000 // update_period, # number of decay steps # 1,000,000 ALE frames  # // Performs floor-division on the values on either side. Then assigns it to the expression on the left.\n",
    "    end_learning_rate=0.01\n",
    ")\n",
    "agent = DqnAgent( # Creates a DQN Agent\n",
    "    tf_env.time_step_spec(), \n",
    "    tf_env.action_spec(), \n",
    "    q_network=q_net, \n",
    "    optimizer=optimizer, \n",
    "    target_update_period=2000, # Period for soft update of the target networks. 2000 x 4 = 8000, 8000 x 4 = 32,000 ALE Frames.\n",
    "    td_errors_loss_fn=tf.keras.losses.Huber(reduction=\"none\"), # The Huber loss function can be used to balance between the Mean Absolute Error and the Mean Squared Error. It is therefore a good loss function for when you have varied data or only a few outliers. Reduction is none so it returns error per instance not the mean error.\n",
    "    gamma=0.99, # discount factor\n",
    "    train_step_counter=train_step, # counts number of training steps\n",
    "    epsilon_greedy=lambda: epsilon_fn(train_step) # function to compute epsilon for a given training step.\n",
    ")\n",
    "agent.initialize() # initialize the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create replay buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer # A batched replay buffer of nests of Tensors which can be sampled uniformly. Would like to implement a prioritized experience replay buffer if time permits.\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec, # specification of the data saved in the replay buffer.(trajectory spec) The DQN agent knows what the collected data looks like\n",
    "    batch_size=tf_env.batch_size, # In our case it's 1.\n",
    "    max_length=1000000 # max size of the replay buffer -> This will require a lot of RAM.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create observer that writes trajectories to the replay buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_observer = replay_buffer.add_batch # an observer that writes trajectorys to the replay buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a custom observer to count the steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowProgress: # custom observer to count steps. \n",
    "    def __init__(self, total):\n",
    "        self.counter=0\n",
    "        self.total=total\n",
    "    def __call__(self, trajectory):\n",
    "        if not trajectory.is_boundary:\n",
    "            self.counter+=1\n",
    "        if self.counter % 100 == 0:\n",
    "            print(\"\\r{}/{}\".format(self.counter, self.total), end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare for metric logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.metrics import tf_metrics \n",
    "train_metrics = [ # metrics\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),#counts undiscounted rewards\n",
    "    tf_metrics.AverageEpisodeLengthMetric(),\n",
    "]\n",
    "\n",
    "from tf_agents.eval.metric_utils import log_metrics\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create main driver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver \n",
    "collect_driver = DynamicStepDriver(\n",
    "    tf_env, # interact with this env\n",
    "    agent.collect_policy, # using this policy\n",
    "    observers=[replay_buffer_observer] + train_metrics,\n",
    "    num_steps=update_period # The number of steps to take in the environment. Collect 4 steps for each training iteration.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create driver to initialize replay buffer with transitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "initial_collect_policy = RandomTFPolicy(tf_env.time_step_spec(), tf_env.action_spec())\n",
    "init_driver = DynamicStepDriver(\n",
    "    tf_env, \n",
    "    initial_collect_policy, \n",
    "    observers=[replay_buffer.add_batch, ShowProgress(20000)],\n",
    "    num_steps=20000 # 80,000 ALE frames\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**initialize replay buffer with transitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/20000"
     ]
    }
   ],
   "source": [
    "final_time_step, final_Policy_state = init_driver.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample 2 sub episodes from the replay buffer - 3 timesteps each**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n",
      "Saving figure sub_episodes_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x680 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.random.set_seed(3) \n",
    "trajectories, buffer_info = next(iter(replay_buffer.as_dataset(\n",
    "    sample_batch_size=2,\n",
    "    num_steps=3,\n",
    "    single_deterministic_pass=False)))\n",
    "\n",
    "plt.figure(figsize=(10, 6.8))\n",
    "for row in range(2):\n",
    "    for col in range(3):\n",
    "        plt.subplot(2, 3, row * 3 + col + 1)\n",
    "        plot_observation(trajectories.observation[row, col].numpy())\n",
    "plt.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0, wspace=0.02)\n",
    "save_fig(\"sub_episodes_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dataset from replay buffer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = replay_buffer.as_dataset( # for our main loop, instead of calling the get_next() method, we use a tf.data.Dataset so we can benefit from parallelism and prefetching.\n",
    "    sample_batch_size=64, # We sample 64 trajectories at each training step (2015 DQN paper), each with 2 steps, e.g. 1 full transition.\n",
    "    num_steps=2,\n",
    "    num_parallel_calls=3 # This dataset willprocess 3 elements in parallel, and prefetch 3 batches.\n",
    ").prefetch(3) # While the model is executing training step s , the input pipeline is reading the data for step s+1 . Doing so reduces the step time to the maximum (as opposed to the sum) of the training and the time it takes to extract the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert main functions to tensorflow functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.utils.common import function\n",
    "collect_driver.run = function(collect_driver.run) # convert main functions to tensorflow functions for performance benefits.\n",
    "agent.train = function(agent.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define function to train agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "def train_agent(n_iterations):\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size) # returns a nested object of type policy_state containing properly initialized Tensors.\n",
    "    iterator = iter(dataset)\n",
    "    for iteration in range(n_iterations):\n",
    "        time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
    "        rewards.append(time_step.reward)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        print(\"\\r{} loss:{:.5f}\".format(iteration, train_loss.loss.numpy()), end=\"\")\n",
    "        if iteration % 1000 == 0:\n",
    "            log_metrics(train_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 0\n",
      "\t\t EnvironmentSteps = 4\n",
      "\t\t AverageReturn = 0.0\n",
      "\t\t AverageEpisodeLength = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 loss:0.00026"
     ]
    }
   ],
   "source": [
    "train_agent(n_iterations=10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Double DQN Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Record video of performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bcart\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\animation.py:879: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim\n",
    "\n",
    "\n",
    "frames = []\n",
    "def save_frames(trajectory):\n",
    "    global frames\n",
    "    frames.append(tf_env.pyenv.envs[0].render(mode=\"rgb_array\"))\n",
    "watch_driver = DynamicStepDriver(\n",
    "    tf_env,\n",
    "    agent.policy,\n",
    "    observers=[save_frames, ShowProgress(1000)],\n",
    "    num_steps=1000)\n",
    "final_time_step, final_policy_state = watch_driver.run()\n",
    "\n",
    "plot_animation(frames)\n",
    "\n",
    "\n",
    "import PIL\n",
    "image_path = os.path.join(\"videos\", \"rl\", \"breakout.gif\")\n",
    "frame_images = [PIL.Image.fromarray(frame) for frame in frames[:150]]\n",
    "frame_images[0].save(image_path, format='GIF',\n",
    "                     append_images=frame_images[1:],\n",
    "                     save_all=True,\n",
    "                     duration=30,\n",
    "                     loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot reward per episode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure double_dqn_reward_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episode\", fontsize=14)\n",
    "plt.ylabel(\"Reward per episode\", fontsize=14)\n",
    "save_fig(\"double_dqn_reward_plot\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "746b5ec03341a8626bd948350cfdc4a299fa8b53d82bfaca140df5bfe1a44143"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
